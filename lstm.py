# -*- coding: utf-8 -*-
"""LSTM

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1R7NBa99ZGicEYOjRvQx-6-rTmKlL5yyN
"""

import pandas as pd
import numpy as np
import random

import sys
from google.colab import drive
drive.mount('/content/drive')
sys.path.append('/content/drive/My Drive/Colab Notebooks')

import statsmodels.api as sm
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_auc_score
from sklearn.metrics import classification_report
from sklearn.metrics import f1_score
from sklearn.inspection import plot_partial_dependence
from sklearn.model_selection import cross_validate
import lightgbm
from imblearn.over_sampling import SMOTE
import cfg

df3 = pd.read_parquet('/content/drive/My Drive/Colab Notebooks/FeaturesMonthlyEdu_False_US_Small_fa9480d4d7-data.parquet')

df3.shape[0]

# Create time series for each fund
funds = df3['fund_id'].unique()
dates = df3['report_date'].unique()
# print(funds, dates)

df3[(df3['fund_id']==funds[1]) & (df3['is_holding']==1)]

# Create time series for each fund
df = pd.DataFrame()
output_temp_1 = pd.DataFrame(columns=('fund_id', 'report_date', 'roe', 'roa', 
                                      'oper_mgn', 'pay_out_ratio', 'pe', 'pbps', 
                                      'div_yld'))
for fund in funds:
  temp = df3[df3['fund_id'] == fund]
  output_temp = pd.DataFrame(columns=('fund_id', 'report_date', 'roe', 'roa', 'oper_mgn', 
                                      'pay_out_ratio', 'pe', 'pbps', 'div_yld'))
  for i in range(len(dates)):
    temp_1 = temp.loc[(temp['report_date'] == dates[i]) & (temp['is_holding'] == 1)]
    row = {'fund_id':fund, 'report_date':dates[i], 'roe':temp_1['roe'].median(), 'roa':temp_1['roa'].median(), 
                'oper_mgn':temp_1['oper_mgn'].median(), 'pay_out_ratio':temp_1['pay_out_ratio'].median(), 
                'pe':temp_1['pe'].median(), 'pbps':temp_1['pbps'].median(), 'div_yld':temp_1['div_yld'].median()}
    output_temp.loc[i] = row
  df = df.append(output_temp)

import math

# Train the model for each fund
temp = df[df['fund_id']==funds[0]]
temp = temp.drop(['fund_id','report_date'], axis=1)
col = temp['roe']

# Convert to supervised dataset
temp = temp.shift(axis=0, periods=1)
temp = temp.rename(columns={'roe':'roe(t-1)', 'roa':'roa(t-1)', 'oper_mgn':'oper_mgn(t-1)', 'pay_out_ratio':'pay_out_ratio(t-1)', 
                     'pe':'pe(t-1)', 'pbps':'pbps(t-1)', 'div_yld':'div_yld(t-1)'})
temp = temp.dropna()
temp['roe(t)'] = col

# Split to train and test sets
values = temp.values
n_train_months = 12 * 5
train = values[:n_train_months, :]
test = values[n_train_months:, :]
# Split into input and output
train_X, train_y = train[:, :-1], train[:, -1]
test_X, test_y = test[:, :-1], test[:, -1]
# Reshape input to be 3D [sample, timesteps, features]
train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))
test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))
print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)

# Design network
import tensorflow as tf
from tensorflow import keras

# Create and fit the LSTM network
model = tf.keras.Sequential()
model.add(tf.keras.layers.LSTM(5, input_shape=(train_X.shape[1], train_X.shape[2]), activation='relu'))
model.add(tf.keras.layers.Dropout(0.2))
model.add(tf.keras.layers.Dense(1, activation='sigmoid'))
model.compile(loss='mae', optimizer='adam')
model.summary()

# fit network
from keras import backend as K

train_X = K.cast_to_floatx(train_X)
train_y = K.cast_to_floatx(train_y)
test_X = K.cast_to_floatx(test_X)
test_y = K.cast_to_floatx(test_y)
history = model.fit(train_X, train_y, epochs=100, batch_size=20, validation_data=(test_X, test_y), verbose=0, shuffle=False)

import matplotlib.pyplot as plt

plt.plot(history.history['loss'], label='train')
plt.plot(history.history['val_loss'], label='test')
plt.legend()
plt.show()

from sklearn.metrics import mean_squared_error
from math import sqrt

yhat = model.predict(test_X)
test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))
rmse = sqrt(mean_squared_error(test_y, yhat))
print('Test RMSE: %.3f' % rmse)

input_fund = df[df['fund_id']==funds[0]]
input_data = input_fund.iloc[-1:,:]
input_data = input_data.drop(['fund_id', 'report_date'], axis=1)
input_data

# test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))
values = input_data.values
input = values
input = input.reshape((1, 1, input.shape[1]))
input = K.cast_to_floatx(input)
model.predict(input)

"""Example for presentation"""

fund1 = pd.read_excel('/content/drive/My Drive/Colab Notebooks/output_CPU.xls')
fund1 = fund1.loc[0]

# Generate all stocks
stocks = df3[df3['report_date']==dates[-1]]
stocks = stocks.drop(['fund_id', 'is_holding', 'report_date', 'fsym_id'], axis=1)
stocks = stocks.drop_duplicates('fsym_regional_id')
stocks.head()

stocks.set_index(['fsym_regional_id'], inplace=True)
stocks = pd.DataFrame(stocks, dtype=np.float)
stocks

fund1 = pd.read_excel('/content/drive/My Drive/Colab Notebooks/output_CPU.xls')
fund1 = fund1.iloc[0]
fund1 = fund1[2:]

fund1 = [eval(i) for i in fund1]

fund1

fund1[3] = eval(fund1[3])
fund1[3] = map(float, fund1[3])
fund1[3]

result = []
for i in range(stocks.shape[0]):
  data = stocks.iloc[i]
  num = np.sqrt((data[0]-fund1[0])**2 + (data[1]-fund1[1])**2 + (data[2]-fund1[2])**2 + 
                   (data[3]-fund1[3])**2 + (data[4]-fund1[4])**2 + 
                   (data[5]-fund1[5])**2 + (data[6]-fund1[6])**2)
  result.append(num)

stocks['score'] = result

stocks.sort_values('score')

